{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9722404-334d-4415-94df-fd8696990122",
   "metadata": {},
   "source": [
    "# Beijing Air Quality Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cedb6b9-2c0c-42c4-9e41-f667cfd7e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d89b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data'\n",
    "\n",
    "# List all CSV files in the data folder\n",
    "csv_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the CSV files and read them into dataframes\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "all_data = pd.concat(dataframes)\n",
    "all_data.drop(columns=['Unnamed: 0', 'No'], inplace=True, errors='ignore')\n",
    "\n",
    "# Create a new column 'date' by parsing year, month, and day columns\n",
    "all_data['date'] = pd.to_datetime(all_data[['year', 'month', 'day']])\n",
    "\n",
    "# Display the first few rows of the consolidated all_dataframe\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bbb65c",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f41829-ed46-4530-97a6-c8eecec426b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Check for missing values\n",
    "print(all_data.isnull().sum())\n",
    "\n",
    "# Fill missing values (if any)\n",
    "all_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Visualize the all_data\n",
    "# Plot all_data for different stations separately\n",
    "stations = all_data['station'].unique()\n",
    "for station in stations:\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    station_data = all_data[all_data['station'] == station]\n",
    "    plt.plot(station_data['date'], station_data['PM2.5'], label=station)\n",
    "    plt.title(f'Beijing Air Quality - PM2.5 Levels at {station}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9404b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Filter data to a station\n",
    "data = all_data[all_data['station'] == 'Dongsi']\n",
    "\n",
    "#Enable tsmode to True to automatically identify time-series variables\n",
    "#Provide the column name that provides the chronological order of your time-series\n",
    "profile = ProfileReport(data, tsmode=True, sortby=\"date\", title=\"Time-Series EDA\")\n",
    "\n",
    "profile.to_file(\"report_timeseries.html\")\n",
    "# profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb1c8a",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76243494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# One hot encode the 'wd' column\n",
    "data = pd.get_dummies(data, columns=['wd'], dtype=int)\n",
    "\n",
    "# Group the data by 'date' and calculate the mean\n",
    "data = data.drop(columns=['station']).groupby('date').agg(['mean']).reset_index()\n",
    "\n",
    "# Decompose the data\n",
    "decomposition = seasonal_decompose(data['PM2.5'].ffill(), model='additive', period=30)\n",
    "\n",
    "# Plot the decomposed components\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, sharex=True, figsize=(15, 5))\n",
    "ax1.plot(data.date, decomposition.observed, label='Observed')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2.plot(data.date, decomposition.trend, label='Trend')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "ax3.plot(data.date, decomposition.seasonal, label='Seasonality')\n",
    "ax3.legend(loc='upper left')\n",
    "\n",
    "ax4.plot(data.date, decomposition.resid, label='Residuals')\n",
    "ax4.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915603de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "residuals = decomposition.resid.dropna()\n",
    "\n",
    "# Plot ACF and PACF\n",
    "lag = 50\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plot_acf(residuals, lags=lag, ax=plt.gca())\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_pacf(residuals, lags=lag, ax=plt.gca())\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.show()\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test\n",
    "adf_result = adfuller(residuals)\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])\n",
    "for key, value in adf_result[4].items():\n",
    "    print('Critical Value (%s): %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699ee5",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83652d-92d2-48b9-920d-136692af77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# ARIMA Model\n",
    "# Split the data into training and testing sets\n",
    "train = data[data['date'] < '2016-06-01']\n",
    "test = data[data['date'] >= '2016-06-01'].ffill()\n",
    "\n",
    "# Fit the ARIMA model\n",
    "arima_model = ARIMA(train['PM2.5'], order=(3, 2, 30))\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "# Forecast\n",
    "arima_forecast = arima_result.forecast(steps=len(test))\n",
    "test['ARIMA_Forecast'] = arima_forecast\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], test['ARIMA_Forecast'].ffill())\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], test['ARIMA_Forecast'].ffill())\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train.date, train['PM2.5'], label='Train')\n",
    "plt.plot(test.date, test['PM2.5'], label='Test')\n",
    "plt.plot(test.date, test['ARIMA_Forecast'], label='ARIMA Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('ARIMA Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train.date[start:], train['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test.date[:window], test['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test.date[:window], test['ARIMA_Forecast'][:window], label='ARIMA Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc1d5c",
   "metadata": {},
   "source": [
    "## ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMAX Model (Univariate Time Series Analysis with Exogenous Variables)\n",
    "# Assuming we have additional exogenous variables like temperature and humidity in the dataset\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Split the data into training and testing sets for ARIMAX model\n",
    "exog_cols = ['TEMP', 'PRES', 'DEWP', 'WSPM', 'SO2', 'NO2', 'CO', 'O3'] + [col for col in train.columns if 'wd' in col]\n",
    "steps = 365\n",
    "train_exog = train[exog_cols].ffill()\n",
    "test_exog = train_exog[-steps:]\n",
    "\n",
    "# Fit the ARIMAX model\n",
    "arimax_model = SARIMAX(train['PM2.5'], exog=train_exog, order=(3, 2, 1))\n",
    "arimax_result = arimax_model.fit()\n",
    "\n",
    "# Forecast with ARIMAX model\n",
    "arimax_forecast = arimax_result.forecast(steps=365, exog=test_exog)\n",
    "test['ARIMAX_Forecast'] = arimax_forecast.clip(0)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], test['ARIMAX_Forecast'].ffill())\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], test['ARIMAX_Forecast'].ffill())\n",
    "\n",
    "# Plot the ARIMAX forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train.date, train['PM2.5'], label='Train')\n",
    "plt.plot(test.date, test['PM2.5'], label='Test')\n",
    "plt.plot(test.date, test['ARIMAX_Forecast'], label='ARIMAX Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('ARIMAX Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train.date[start:], train['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test.date[:window], test['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test.date[:window], test['ARIMAX_Forecast'][:window], label='ARIMAX Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd2ef65",
   "metadata": {},
   "source": [
    "## SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46106f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# SARIMAX Model (Multivariate Time Series Analysis)\n",
    "# Assuming we have additional exogenous variables like temperature and humidity in the dataset\n",
    "\n",
    "# Split the data into training and testing sets for SARIMAX model\n",
    "steps = 365\n",
    "train_exog = train[exog_cols].ffill()\n",
    "test_exog = train_exog[-steps:]\n",
    "\n",
    "# Fit the SARIMAX model\n",
    "sarimax_model = SARIMAX(train['PM2.5'], exog=train_exog, order=(3, 2, 1), seasonal_order=(1, 1, 1, 7))\n",
    "sarimax_result = sarimax_model.fit()\n",
    "\n",
    "# Forecast with SARIMAX model\n",
    "sarimax_forecast = sarimax_result.forecast(steps=steps, exog=test_exog)\n",
    "test['SARIMAX_Forecast'] = sarimax_forecast.clip(0)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], test['SARIMAX_Forecast'].ffill())\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], test['SARIMAX_Forecast'].ffill())\n",
    "\n",
    "# Plot the SARIMAX forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train.date, train['PM2.5'], label='Train')\n",
    "plt.plot(test.date, test['PM2.5'], label='Test')\n",
    "plt.plot(test.date, test['SARIMAX_Forecast'], label='SARIMAX Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('SARIMAX Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ee7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train.date[start:], train['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test.date[:window], test['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test.date[:window], test['SARIMAX_Forecast'][:window], label='SARIMAX Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f98d7",
   "metadata": {},
   "source": [
    "## Vector Autoregression (VAR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4930388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Perform Granger's causality test - only between 2 variables at a time\n",
    "# We will test if TEMP and DEWP can predict PM2.5\n",
    "temp_df = data[['TEMP', 'DEWP']].dropna()\n",
    "max_lag = 12\n",
    "granger_test_result = grangercausalitytests(temp_df, max_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9eb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Prepare the data for VAR model\n",
    "# We will use PM2.5, TEMP, and DEWP as variables\n",
    "var_data = data[['date', 'PM2.5'] + exog_cols].ffill()\n",
    "var_data.set_index('date', inplace=True, drop=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_var = var_data[var_data.index < '2016-06-01']\n",
    "test_var = var_data[var_data.index >= '2016-06-01']\n",
    "\n",
    "# Fit the VAR model\n",
    "var_model = VAR(train_var)\n",
    "var_result = var_model.fit(maxlags=15, ic='aic')\n",
    "\n",
    "# Forecast\n",
    "lag_order = var_result.k_ar\n",
    "var_forecast_input = train_var.values[-lag_order:]\n",
    "var_forecast = var_result.forecast(y=var_forecast_input, steps=len(test_var))\n",
    "\n",
    "# Convert forecast to DataFrame\n",
    "var_forecast_df = pd.DataFrame(var_forecast, index=test_var.index, columns=train_var.columns)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test_var['PM2.5'], var_forecast_df['PM2.5'].ffill())\n",
    "mape = mean_absolute_percentage_error(test_var['PM2.5'], var_forecast_df['PM2.5'].ffill())\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train_var['PM2.5'], label='Train')\n",
    "plt.plot(test_var['PM2.5'], label='Test')\n",
    "plt.plot(var_forecast_df['PM2.5'], label='VAR Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('VAR Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train_var.index[start:], train_var['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test_var.index[:window], test_var['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test_var.index[:window], var_forecast_df['PM2.5'][:window], label='VAR Forecast')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab54b75",
   "metadata": {},
   "source": [
    "## Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a24e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Prophet Model\n",
    "# Prepare the data for Prophet\n",
    "prophet_data = train.rename(columns={'date': 'ds', 'PM2.5': 'y'})\n",
    "prophet_data.columns = prophet_data.columns.droplevel(1)\n",
    "\n",
    "# Fit the Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(prophet_data)\n",
    "\n",
    "# Make future dataframe\n",
    "future = prophet_model.make_future_dataframe(periods=365)\n",
    "forecast = prophet_model.predict(future)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], forecast['yhat'].tail(len(test)))\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], forecast['yhat'].tail(len(test)))\n",
    "\n",
    "# Plot the forecast\n",
    "fig = prophet_model.plot(forecast)\n",
    "plt.title('Prophet Forecast vs Actual: MAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.show()\n",
    "\n",
    "# Display the forecast components\n",
    "fig2 = prophet_model.plot_components(forecast)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
