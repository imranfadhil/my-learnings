{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9722404-334d-4415-94df-fd8696990122",
   "metadata": {},
   "source": [
    "# Beijing Air Quality Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cedb6b9-2c0c-42c4-9e41-f667cfd7e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d89b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data'\n",
    "\n",
    "# List all CSV files in the data folder\n",
    "csv_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the CSV files and read them into dataframes\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "all_data = pd.concat(dataframes)\n",
    "all_data.drop(columns=['Unnamed: 0', 'No'], inplace=True, errors='ignore')\n",
    "\n",
    "# Create a new column 'date' by parsing year, month, and day columns\n",
    "all_data['date'] = pd.to_datetime(all_data[['year', 'month', 'day']])\n",
    "\n",
    "# Display the first few rows of the consolidated all_dataframe\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bbb65c",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f41829-ed46-4530-97a6-c8eecec426b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Check for missing values\n",
    "print(all_data.isnull().sum())\n",
    "\n",
    "# Fill missing values (if any)\n",
    "all_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Visualize the all_data\n",
    "# Plot all_data for different stations separately\n",
    "stations = all_data['station'].unique()\n",
    "for station in stations:\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    station_data = all_data[all_data['station'] == station]\n",
    "    plt.plot(station_data['date'], station_data['PM2.5'], label=station)\n",
    "    plt.title(f'Beijing Air Quality - PM2.5 Levels at {station}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9404b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Filter data to a station\n",
    "data = all_data[all_data['station'] == 'Dongsi']\n",
    "\n",
    "#Enable tsmode to True to automatically identify time-series variables\n",
    "#Provide the column name that provides the chronological order of your time-series\n",
    "profile = ProfileReport(data, tsmode=True, sortby=\"date\", title=\"Time-Series EDA\")\n",
    "\n",
    "profile.to_file(\"report_timeseries.html\")\n",
    "# profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb1c8a",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76243494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# One hot encode the 'wd' column\n",
    "data = pd.get_dummies(data, columns=['wd'], dtype=int)\n",
    "\n",
    "# Group the data by 'date' and calculate the mean\n",
    "data = data.drop(columns=['station']).groupby('date').agg(['mean']).reset_index()\n",
    "data.columns = data.columns.droplevel(1)\n",
    "\n",
    "# Decompose the data\n",
    "decomposition = seasonal_decompose(data['PM2.5'].ffill(), model='additive', period=30)\n",
    "\n",
    "# Plot the decomposed components\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, sharex=True, figsize=(15, 5))\n",
    "ax1.plot(data.date, decomposition.observed, label='Observed')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2.plot(data.date, decomposition.trend, label='Trend')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "ax3.plot(data.date, decomposition.seasonal, label='Seasonality')\n",
    "ax3.legend(loc='upper left')\n",
    "\n",
    "ax4.plot(data.date, decomposition.resid, label='Residuals')\n",
    "ax4.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53737bdc-ffa5-4baf-b988-cf9501260d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "input_data = data['PM2.5'].ffill().dropna()\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test\n",
    "adf_result = adfuller(input_data)\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])\n",
    "for key, value in adf_result[4].items():\n",
    "    print('Critical Value (%s): %.3f' % (key, value))\n",
    "\n",
    "# Plot ACF and PACF\n",
    "lag = 50\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plot_acf(input_data, lags=lag, ax=plt.gca())\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_pacf(input_data, lags=lag, ax=plt.gca())\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e51778-e304-48dd-8279-8ba30711855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "\n",
    "p, d, q = 2, 0, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699ee5",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83652d-92d2-48b9-920d-136692af77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# ARIMA Model\n",
    "# Split the data into training and testing sets\n",
    "train = data[data['date'] < '2016-06-01']\n",
    "test = data[data['date'] >= '2016-06-01'].ffill()\n",
    "\n",
    "# Fit the ARIMA model\n",
    "arima_model = ARIMA(train['PM2.5'], order=(p, d, q))\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "# Forecast\n",
    "arima_forecast = arima_result.forecast(steps=len(test))\n",
    "test['ARIMA_Forecast'] = arima_forecast\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], test['ARIMA_Forecast'].ffill())\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], test['ARIMA_Forecast'].ffill())\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train.date, train['PM2.5'], label='Train')\n",
    "plt.plot(test.date, test['PM2.5'], label='Test')\n",
    "plt.plot(test.date, test['ARIMA_Forecast'], label='ARIMA Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('ARIMA Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train.date[start:], train['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test.date[:window], test['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test.date[:window], test['ARIMA_Forecast'][:window], label='ARIMA Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc1d5c",
   "metadata": {},
   "source": [
    "## ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMAX Model (Univariate Time Series Analysis with Exogenous Variables)\n",
    "# Assuming we have additional exogenous variables like temperature and humidity in the dataset\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Split the data into training and testing sets for ARIMAX model\n",
    "exog_cols = ['TEMP', 'PRES', 'DEWP', 'WSPM', 'SO2', 'NO2', 'CO', 'O3'] + [col for col in train.columns if 'wd' in col]\n",
    "exog_cols = ['TEMP', 'PRES', 'DEWP', 'WSPM', 'SO2', 'NO2', 'CO', 'O3'] + [col for col in train.columns if 'wd' in col]\n",
    "steps = 365\n",
    "train_exog = train[exog_cols].ffill()\n",
    "test_exog = train_exog[-steps:]\n",
    "\n",
    "# Fit the ARIMAX model\n",
    "arimax_model = SARIMAX(train['PM2.5'], exog=train_exog, order=(p, d, q))\n",
    "arimax_result = arimax_model.fit()\n",
    "\n",
    "# Forecast with ARIMAX model\n",
    "arimax_forecast = arimax_result.forecast(steps=365, exog=test_exog)\n",
    "test['ARIMAX_Forecast'] = arimax_forecast.clip(0)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], test['ARIMAX_Forecast'].ffill())\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], test['ARIMAX_Forecast'].ffill())\n",
    "\n",
    "# Plot the ARIMAX forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train.date, train['PM2.5'], label='Train')\n",
    "plt.plot(test.date, test['PM2.5'], label='Test')\n",
    "plt.plot(test.date, test['ARIMAX_Forecast'], label='ARIMAX Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('ARIMAX Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train.date[start:], train['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test.date[:window], test['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test.date[:window], test['ARIMAX_Forecast'][:window], label='ARIMAX Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd2ef65",
   "metadata": {},
   "source": [
    "## SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46106f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# SARIMAX Model (Multivariate Time Series Analysis)\n",
    "# Assuming we have additional exogenous variables like temperature and humidity in the dataset\n",
    "\n",
    "# Split the data into training and testing sets for SARIMAX model\n",
    "steps = 365\n",
    "train_exog = train[exog_cols].ffill()\n",
    "test_exog = train_exog[-steps:]\n",
    "\n",
    "# Fit the SARIMAX model\n",
    "sarimax_model = SARIMAX(train['PM2.5'], exog=train_exog, order=(p, d, q), seasonal_order=(1, 1, 1, 7))\n",
    "sarimax_result = sarimax_model.fit()\n",
    "\n",
    "# Forecast with SARIMAX model\n",
    "sarimax_forecast = sarimax_result.forecast(steps=steps, exog=test_exog)\n",
    "test['SARIMAX_Forecast'] = sarimax_forecast.clip(0)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], test['SARIMAX_Forecast'].ffill())\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], test['SARIMAX_Forecast'].ffill())\n",
    "\n",
    "# Plot the SARIMAX forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train.date, train['PM2.5'], label='Train')\n",
    "plt.plot(test.date, test['PM2.5'], label='Test')\n",
    "plt.plot(test.date, test['SARIMAX_Forecast'], label='SARIMAX Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('SARIMAX Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ee7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train.date[start:], train['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test.date[:window], test['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test.date[:window], test['SARIMAX_Forecast'][:window], label='SARIMAX Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f98d7",
   "metadata": {},
   "source": [
    "## Vector Autoregression (VAR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4930388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Perform Granger's causality test\n",
    "maxlag=12\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test'):    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "columns = ['PM2.5'] + exog_cols\n",
    "grangers_causality_result = grangers_causation_matrix(data[columns].dropna(), variables=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7685a22-1748-49d2-ba0c-e6150e763067",
   "metadata": {},
   "outputs": [],
   "source": [
    "grangers_causality_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9eb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Prepare the data for VAR model\n",
    "new_exog_cols = [col for col in exog_cols if 'wd' not in col]\n",
    "var_data = data[['date', 'PM2.5'] + new_exog_cols].ffill()\n",
    "var_data.set_index('date', inplace=True, drop=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_var = var_data[var_data.index < '2016-06-01']\n",
    "test_var = var_data[var_data.index >= '2016-06-01']\n",
    "\n",
    "# Fit the VAR model\n",
    "var_model = VAR(train_var)\n",
    "var_result = var_model.fit(maxlags=15, ic='aic')\n",
    "\n",
    "# Forecast\n",
    "lag_order = var_result.k_ar\n",
    "var_forecast_input = train_var.values[-lag_order:]\n",
    "var_forecast = var_result.forecast(y=var_forecast_input, steps=len(test_var))\n",
    "\n",
    "# Convert forecast to DataFrame\n",
    "var_forecast_df = pd.DataFrame(var_forecast, index=test_var.index, columns=train_var.columns)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test_var['PM2.5'], var_forecast_df['PM2.5'].ffill())\n",
    "mape = mean_absolute_percentage_error(test_var['PM2.5'], var_forecast_df['PM2.5'].ffill())\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(train_var['PM2.5'], label='Train')\n",
    "plt.plot(test_var['PM2.5'], label='Test')\n",
    "plt.plot(var_forecast_df['PM2.5'], label='VAR Forecast: \\nMAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.title('VAR Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2866f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train_var.index[start:], train_var['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test_var.index[:window], test_var['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test_var.index[:window], var_forecast_df['PM2.5'][:window], label='VAR Forecast')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab54b75",
   "metadata": {},
   "source": [
    "## Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a24e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Prophet Model\n",
    "# Prepare the data for Prophet\n",
    "prophet_data = train.rename(columns={'date': 'ds', 'PM2.5': 'y'})\n",
    "\n",
    "# Fit the Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(prophet_data)\n",
    "\n",
    "# Make future dataframe\n",
    "period = 365\n",
    "future = prophet_model.make_future_dataframe(periods=period)\n",
    "forecast = prophet_model.predict(future)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test['PM2.5'], forecast['yhat'].tail(len(test)))\n",
    "mape = mean_absolute_percentage_error(test['PM2.5'], forecast['yhat'].tail(len(test)))\n",
    "\n",
    "# Plot the forecast\n",
    "fig = prophet_model.plot(forecast)\n",
    "plt.title('Prophet Forecast vs Actual: MAE=%.2f, MAPE=%.2f' % (mae, mape))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.show()\n",
    "\n",
    "# Display the forecast components\n",
    "fig2 = prophet_model.plot_components(forecast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ea198-7b28-42b7-94b3-4ee9eafc2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the data with a given range\n",
    "@interact(\n",
    "        start=widgets.IntSlider(min=0, max=len(data)-100, step=10, value=0),\n",
    "        window=widgets.IntSlider(min=10, max=len(test), step=50, value=len(test))\n",
    ")\n",
    "def plot_data(start, window):\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(train_var.index[start:], train_var['PM2.5'][start:], label='Train')\n",
    "    plt.plot(test_var.index[:window], test_var['PM2.5'][:window], label='Test')\n",
    "    plt.plot(test_var.index[:window], forecast['yhat'].tail(window), label='VAR Forecast')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.title('PM2.5 Levels Over Time')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
